{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexisdr/uned-tfg/blob/main/UNED-TFG-3-train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "H7uHO0xNibAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/drive/My Drive/CorpusPFG/'\n",
        "\n",
        "#Datasets procesados\n",
        "dataset_path = base_path + 'Dataset'\n",
        "\n",
        "#Model parameters\n",
        "#CHECKPOINT = \"allenai/led-base-16384\"\n",
        "#CHECKPOINT = \"allenai/longformer-base-4096\"\n",
        "#CHECKPOINT = \"bert-base-multilingual-cased\"\n",
        "CHECKPOINT = \"PlanTL-GOB-ES/bsc-bio-es\"\n",
        "#CHECKPOINT = \"PlanTL-GOB-ES/bsc-bio-ehr-es\"\n",
        "#CHECKPOINT = \"PlanTL-GOB-ES/longformer-base-4096-biomedical-clinical-es\"\n",
        "NUM_EPOCHS = 1\n",
        "BATCH_SIZE = 16\n",
        "METRIC_NAME = \"f1\"\n",
        "HUGGING_FACE_TOKEN = \"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\"\n",
        "\n",
        "METRIC_AVERGE = \"micro\"\n",
        "\n",
        "subir_a_hugging_faces = True\n",
        "reducir_tamanyo_dataset_para_pruebas = False"
      ],
      "metadata": {
        "id": "rhtVG5QtiYkr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set-up environment\n",
        "\n",
        "First, we install the libraries which we'll use: HuggingFace Transformers and Datasets."
      ],
      "metadata": {
        "id": "cnxpm2C6Fqxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets evaluate transformers[sentencepiece] accelerate\n",
        "# To run the training on TPU, you will need to uncomment the following line:\n",
        "#!pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "2LNboFxnxK--",
        "outputId": "d3f82326-43e7-4fda-9390-14981fbf4d76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3021, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 160, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 241, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 499, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 631, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2736, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3023, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3033, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3094, in parse_requirements\n",
            "    yield Requirement(line)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3101, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n",
            "    req = REQUIREMENT.parseString(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4959, in parseImpl\n",
            "    loc, tokens = self_expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 856, in _parseNoCache\n",
            "    tokens = fn(instring, tokens_start, ret_tokens)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 291, in wrapper\n",
            "    ret = func(*args[limit:])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 71, in <lambda>\n",
            "    lambda s, l, t: Marker(s[t._original_start : t._original_end])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/markers.py\", line 278, in __init__\n",
            "    self._markers = _coerce_parse_result(MARKER.parseString(marker))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 5226, in parseImpl\n",
            "    return super().parseImpl(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 811, in _parseNoCache\n",
            "    pre_loc = self.preParse(instring, loc)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 758, in preParse\n",
            "    if self.ignoreExprs:\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1732, in isEnabledFor\n",
            "    return self._cache[level]\n",
            "KeyError: 50\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 214, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 197, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1523, in critical\n",
            "    if self.isEnabledFor(CRITICAL):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1740, in isEnabledFor\n",
            "    level >= self.getEffectiveLevel()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1718, in getEffectiveLevel\n",
            "    while logger:\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset\n",
        "\n",
        "Next, let's load a multi-label text classification dataset from files.\n"
      ],
      "metadata": {
        "id": "UujvKjusiVfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "UisW21-kiQqd",
        "outputId": "91b2ccc2-29ba-4daf-8189-230a929d1780"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 3>\u001b[0m:\u001b[94m3\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/google/colab/\u001b[0m\u001b[1;33mdrive.py\u001b[0m:\u001b[94m103\u001b[0m in \u001b[92mmount\u001b[0m                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m100 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m101 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mmount\u001b[0m(mountpoint, force_remount=\u001b[94mFalse\u001b[0m, timeout_ms=\u001b[94m120000\u001b[0m, readonly=\u001b[94mFalse\u001b[0m):             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m102 \u001b[0m\u001b[2;90m  \u001b[0m\u001b[33m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m103 \u001b[2m  \u001b[0m\u001b[94mreturn\u001b[0m _mount(                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m104 \u001b[0m\u001b[2m│     \u001b[0mmountpoint,                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m105 \u001b[0m\u001b[2m│     \u001b[0mforce_remount=force_remount,                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m106 \u001b[0m\u001b[2m│     \u001b[0mtimeout_ms=timeout_ms,                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/google/colab/\u001b[0m\u001b[1;33mdrive.py\u001b[0m:\u001b[94m132\u001b[0m in \u001b[92m_mount\u001b[0m                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m129 \u001b[0m\u001b[2m│     \u001b[0m\u001b[94melse\u001b[0m _os.environ[\u001b[33m'\u001b[0m\u001b[33mTBE_CREDS_ADDR\u001b[0m\u001b[33m'\u001b[0m]                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m130 \u001b[0m\u001b[2m  \u001b[0m)                                                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m131 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mif\u001b[0m ephemeral:                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m132 \u001b[2m│   \u001b[0m_message.blocking_request(                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[33m'\u001b[0m\u001b[33mrequest_auth\u001b[0m\u001b[33m'\u001b[0m, request={\u001b[33m'\u001b[0m\u001b[33mauthType\u001b[0m\u001b[33m'\u001b[0m: \u001b[33m'\u001b[0m\u001b[33mdfs_ephemeral\u001b[0m\u001b[33m'\u001b[0m}, timeout_sec=\u001b[94mNone\u001b[0m            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m134 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/google/colab/\u001b[0m\u001b[1;33m_message.py\u001b[0m:\u001b[94m176\u001b[0m in \u001b[92mblocking_request\u001b[0m         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m  \u001b[0mrequest_id = send_request(                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m174 \u001b[0m\u001b[2m│     \u001b[0mrequest_type, request, parent=parent, expect_reply=\u001b[94mTrue\u001b[0m                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m175 \u001b[0m\u001b[2m  \u001b[0m)                                                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m176 \u001b[2m  \u001b[0m\u001b[94mreturn\u001b[0m read_reply_from_input(request_id, timeout_sec)                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m177 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/google/colab/\u001b[0m\u001b[1;33m_message.py\u001b[0m:\u001b[94m96\u001b[0m in \u001b[92mread_reply_from_input\u001b[0m     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 93 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mwhile\u001b[0m \u001b[95mnot\u001b[0m deadline \u001b[95mor\u001b[0m time.time() < deadline:                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m│   \u001b[0mreply = _read_next_input_message()                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m reply == _NOT_READY \u001b[95mor\u001b[0m \u001b[95mnot\u001b[0m \u001b[96misinstance\u001b[0m(reply, \u001b[96mdict\u001b[0m):                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 96 \u001b[2m│     \u001b[0mtime.sleep(\u001b[94m0.025\u001b[0m)                                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 97 \u001b[0m\u001b[2m│     \u001b[0m\u001b[94mcontinue\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m (                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   │   \u001b[0mreply.get(\u001b[33m'\u001b[0m\u001b[33mtype\u001b[0m\u001b[33m'\u001b[0m) == \u001b[33m'\u001b[0m\u001b[33mcolab_reply\u001b[0m\u001b[33m'\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 3&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/google/colab/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">drive.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">103</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">mount</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">100 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">101 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">mount</span>(mountpoint, force_remount=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>, timeout_ms=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">120000</span>, readonly=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>):             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">102 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">  </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>103 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _mount(                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">104 │     </span>mountpoint,                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">105 │     </span>force_remount=force_remount,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">106 │     </span>timeout_ms=timeout_ms,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/google/colab/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">drive.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">132</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_mount</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">129 │     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> _os.environ[<span style=\"color: #808000; text-decoration-color: #808000\">'TBE_CREDS_ADDR'</span>]                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">130   </span>)                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">131   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> ephemeral:                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>132 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>_message.blocking_request(                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">133 │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">'request_auth'</span>, request={<span style=\"color: #808000; text-decoration-color: #808000\">'authType'</span>: <span style=\"color: #808000; text-decoration-color: #808000\">'dfs_ephemeral'</span>}, timeout_sec=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">134 │   </span>)                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/google/colab/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_message.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">176</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">blocking_request</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173   </span>request_id = send_request(                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">174 │     </span>request_type, request, parent=parent, expect_reply=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">175   </span>)                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>176 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> read_reply_from_input(request_id, timeout_sec)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">177 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/google/colab/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_message.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">96</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">read_reply_from_input</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 93   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">while</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> deadline <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> time.time() &lt; deadline:                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 94 │   </span>reply = _read_next_input_message()                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 95 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> reply == _NOT_READY <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(reply, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">dict</span>):                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 96 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>time.sleep(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.025</span>)                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 97 │     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">continue</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 98 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 99 │   │   </span>reply.get(<span style=\"color: #808000; text-decoration-color: #808000\">'type'</span>) == <span style=\"color: #808000; text-decoration-color: #808000\">'colab_reply'</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "dataset = DatasetDict.load_from_disk(dataset_path)"
      ],
      "metadata": {
        "id": "knWPWK7GAHoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "UzxNkhLMCfOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the an example of the training split:"
      ],
      "metadata": {
        "id": "NAQXoTKZCo52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (reducir_tamanyo_dataset_para_pruebas):\n",
        "  dataset_train_reducido = dataset['train'].train_test_split(test_size=0.1)\n",
        "  dataset['train']=dataset_train_reducido['test']\n",
        "\n",
        "  dataset_test_reducido = dataset['test'].train_test_split(test_size=0.1)\n",
        "  dataset['test']=dataset_test_reducido['test']"
      ],
      "metadata": {
        "id": "9wDQlIiRhZod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0]"
      ],
      "metadata": {
        "id": "FFcoXzf_Cifb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'].features"
      ],
      "metadata": {
        "id": "w6G4aKeCCmWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset consists of tweets, labeled with one or more emotions. \n",
        "\n",
        "Let's create a list that contains the labels, as well as 2 dictionaries that map labels to integers and back."
      ],
      "metadata": {
        "id": "P-PabaGoC4Oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import ClassLabel\n",
        "\n",
        "class2label = dataset['train'].features[\"label\"]\n",
        "id2label = {idx:label for idx, label in enumerate(class2label._int2str)}\n",
        "label2id = class2label._str2int\n",
        "\n",
        "print(class2label)\n",
        "print(id2label)\n",
        "print(label2id)"
      ],
      "metadata": {
        "id": "PLpNdkaYC5ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class2label.int2str(256)"
      ],
      "metadata": {
        "id": "jAJlkwDSFSKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess data\n",
        "\n",
        "As models like BERT don't expect text as direct input, but rather `input_ids`, etc., we tokenize the text using the tokenizer. Here I'm using the `AutoTokenizer` API, which will automatically load the appropriate tokenizer based on the checkpoint on the hub."
      ],
      "metadata": {
        "id": "ePcPhmt4XlUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XY-jgD9uFmpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification, DataCollatorForLanguageModeling, DataCollatorWithPadding\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT, use_auth_token=HUGGING_FACE_TOKEN)\n",
        "\n",
        "def preprocess_data(example):\n",
        "  # toma el texto\n",
        "  text = example[\"text\"]\n",
        "  # lo codifica con tokenizador\n",
        "  encoding = tokenizer(text, padding=\"max_length\", truncation=True)  \n",
        "  \n",
        "  labels = example[\"label_list\"]\n",
        "  # crea una matriz del tamaño del texto y las clases a entrenar\n",
        "  labels_matrix = np.zeros((len(text), class2label.num_classes))\n",
        "\n",
        "  for clase in labels:\n",
        "    labels_matrix[:, clase] = 1\n",
        "\n",
        "  # crea un vector del tamaño de las clases a entrenar\n",
        "  #label_array = np.zeros(class2label.num_classes)\n",
        "  # por cada clase de la muestra, pone a 1 el valor dentro del vector\n",
        "  #for clase in example[\"label_list\"]:\n",
        "  #  label_array[clase] = 1\n",
        "\n",
        "  # asigna el vector con los clases correspondientes activas\n",
        "  encoding[\"labels\"] = labels_matrix.tolist()\n",
        "\n",
        "  return encoding"
      ],
      "metadata": {
        "id": "FgYEmR1RxDBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0]['text']"
      ],
      "metadata": {
        "id": "BmMDnf_4G7l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_data(dataset['train'][0])"
      ],
      "metadata": {
        "id": "-ApAkTTlGo_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_dataset = dataset.map(\n",
        "    preprocess_data, batched=True, remove_columns=dataset['train'].column_names)\n",
        "encoded_dataset.set_format(\"torch\")"
      ],
      "metadata": {
        "id": "0y0vnLXxyOjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_dataset"
      ],
      "metadata": {
        "id": "NsCXrJhDIVc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = encoded_dataset['train'][0]\n",
        "tokenizer.decode(example['input_ids'])"
      ],
      "metadata": {
        "id": "_LfdUdPdI8N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example['labels']"
      ],
      "metadata": {
        "id": "OLNwJnAlIjwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#class2label.int2str(example['labels'].item())"
      ],
      "metadata": {
        "id": "OmlJ_JoaJJSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model!\n",
        "\n",
        "We are going to train the model using HuggingFace's Trainer API."
      ],
      "metadata": {
        "id": "5ODEcFBkJgAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    encoded_dataset[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    encoded_dataset[\"validation\"], batch_size=8, collate_fn=data_collator\n",
        ")\n",
        "\n",
        "for batch in train_dataloader:\n",
        "    break\n",
        "{k: v.shape for k, v in batch.items()}"
      ],
      "metadata": {
        "id": "RQU7TCbP9oq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "from accelerate import Accelerator\n",
        "from transformers import AdamW, AutoModelForSequenceClassification, get_scheduler\n",
        "import torch\n",
        "from transformers import get_scheduler  \n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score\n",
        "from transformers import EvalPrediction\n",
        "\n",
        "#metrics\n",
        "def multi_label_metrics(predictions, labels, threshold=0.9):\n",
        "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "    # next, use threshold to turn them into integer predictions\n",
        "    y_pred = np.zeros(probs.shape)\n",
        "    y_pred[np.where(probs >= threshold)] = 1\n",
        "    # finally, compute metrics\n",
        "    y_true = labels\n",
        "      \n",
        "    precision_score_value = precision_score(y_true, y_pred, average=METRIC_AVERGE)\n",
        "    recall_score_value = recall_score(y_true, y_pred, average=METRIC_AVERGE)\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average=METRIC_AVERGE)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred, average=METRIC_AVERGE)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    # return as dictionary\n",
        "    metrics = {\n",
        "      'precision_score': precision_score_value,\n",
        "      'recall_score': recall_score_value,\n",
        "      'f1': f1_micro_average,\n",
        "      'roc_auc': roc_auc,\n",
        "      'accuracy': accuracy, \n",
        "      'y_pred': y_pred, \n",
        "      'y_true': y_true}\n",
        "    return metrics\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    print (\"p\")\n",
        "    print (p)\n",
        "    print (\"p.predictions\")\n",
        "    print (p.predictions)\n",
        "    print (\"len(p.predictions)\")\n",
        "    print (len(p.predictions))\n",
        "    print (\"len(p.predictions[0])\")\n",
        "    print (len(p.predictions[0]))\n",
        "    preds = p.predictions[0] if isinstance(p.predictions, \n",
        "            tuple) else p.predictions\n",
        "\n",
        "    return multi_label_metrics(predictions=preds, labels=p.label_ids)\n",
        "\n",
        "def training_model():\n",
        "\n",
        "  accelerator = Accelerator()\n",
        "\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        CHECKPOINT, \n",
        "        num_labels=class2label.num_classes, \n",
        "        id2label = id2label, \n",
        "        label2id = label2id,\n",
        "        problem_type = \"multi_label_classification\",\n",
        "        use_auth_token = HUGGING_FACE_TOKEN) #\"single_label_classification\"\n",
        "\n",
        "  device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "  model.to(device)\n",
        "\n",
        "  optimizer = AdamW(model.parameters(), lr=3e-5)\n",
        "  train_dl, eval_dl, model, optimizer = accelerator.prepare(\n",
        "      train_dataloader, eval_dataloader, model, optimizer\n",
        "  )\n",
        "\n",
        "  num_training_steps = NUM_EPOCHS * len(train_dataloader)\n",
        "  lr_scheduler = get_scheduler(\n",
        "      \"linear\",\n",
        "      optimizer=optimizer,\n",
        "      num_warmup_steps=0,\n",
        "      num_training_steps=num_training_steps,\n",
        "  )\n",
        "\n",
        "  progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "  training_args = TrainingArguments(\n",
        "      evaluation_strategy=\"epoch\", \n",
        "      save_strategy = \"epoch\",\n",
        "      load_best_model_at_end=True,\n",
        "      output_dir= MODEL_OUTPUT_DIR, \n",
        "      per_device_train_batch_size=BATCH_SIZE,\n",
        "      per_device_eval_batch_size=BATCH_SIZE,\n",
        "      num_train_epochs=NUM_EPOCHS,\n",
        "      learning_rate=2e-5,\n",
        "      weight_decay=0.01,\n",
        "      metric_for_best_model=METRIC_NAME,\n",
        "      hub_token=HUGGING_FACE_TOKEN,\n",
        "      hub_private_repo=True,\n",
        "      push_to_hub=subir_a_hugging_faces) \n",
        "\n",
        "  trainer = Trainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      data_collator=data_collator,\n",
        "      train_dataset=encoded_dataset[\"train\"],\n",
        "      eval_dataset=encoded_dataset[\"validation\"],\n",
        "      compute_metrics=compute_metrics,\n",
        "      optimizers=(optimizer,lr_scheduler)\n",
        "  )\n",
        "\n",
        "  trainer.train()\n",
        "\n",
        "  if (subir_a_hugging_faces);\n",
        "    tokenizer.push_to_hub(\n",
        "        MODEL_OUTPUT_DIR, private=True, \n",
        "        use_auth_token=HUGGING_FACE_TOKEN)"
      ],
      "metadata": {
        "id": "EKJXUS7Z_7eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import notebook_launcher\n",
        "\n",
        "MODEL_OUTPUT_DIR = \"uned-tfg-08.19\"\n",
        "notebook_launcher(training_model)"
      ],
      "metadata": {
        "id": "gCKnrKgTKgbt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}